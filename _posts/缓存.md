# 缓存

## 缓存失效策略

缓存失效策略是指在缓存中存储的数据何时应该被视为无效或过期，需要从数据源重新获取或更新。常见的缓存失效策略包括基于时间的策略（TTL）和基于数据访问模式的策略（LRU、LFU等）。下面将详细描述这些策略的算法与实现：

### 1. 基于时间的策略（TTL）

#### 算法原理：
每个缓存条目都附带一个过期时间（Time To Live），一旦超过这个时间，缓存条目就被标记为无效，需要重新获取或更新。

#### 实现方式：
在缓存条目中存储过期时间戳，定期检查缓存条目的过期状态，并根据需要进行失效处理。

```python
class Cache:
    def __init__(self):
        self.cache = {}
    
    def get(self, key):
        if key in self.cache and self.cache[key]['expiry'] > time.now():
            return self.cache[key]['value']
        else:
            return None
    
    def set(self, key, value, ttl):
        expiry = time.now() + ttl
        self.cache[key] = {'value': value, 'expiry': expiry}
```

### 2. 基于数据访问模式的策略

#### 2.1 LRU（Least Recently Used）

##### 算法原理：
缓存中最近最少使用的条目将被淘汰。

##### 实现方式：
使用一个有序列表或链表（如双向链表）来维护缓存中条目的访问顺序，每次访问一个条目时，将其移动到列表的头部。当缓存空间不足时，淘汰列表尾部的条目。

```python
from collections import OrderedDict

class LRUCache:
    def __init__(self, capacity):
        self.capacity = capacity
        self.cache = OrderedDict()
    
    def get(self, key):
        if key in self.cache:
            value = self.cache.pop(key)
            self.cache[key] = value
            return value
        else:
            return None
    
    def set(self, key, value):
        if key in self.cache:
            self.cache.pop(key)
        elif len(self.cache) >= self.capacity:
            self.cache.popitem(last=False) # Remove the least recently used item
        self.cache[key] = value
```

#### 2.2 LFU（Least Frequently Used）

##### 算法原理：
缓存中最少访问的条目将被淘汰。

##### 实现方式：
除了记录访问时间，还需要记录访问次数。每次访问一个条目时，将其访问次数加一。当缓存空间不足时，淘汰访问次数最少的条目。

### 总结

缓存失效策略的选择取决于系统的需求和场景。基于时间的策略适用于对实效性要求较强的数据，而基于数据访问模式的策略适用于对访问模式较为敏感的数据。通过合理选择和实现缓存失效策略，可以提高系统的性能和效率。

Java 实现基于时间的缓存失效策略（TTL）和基于数据访问模式的缓存失效策略（LRU）的示例：

### 基于时间的策略（TTL）

```java
import java.util.HashMap;

public class TTLCache<K, V> {
    private HashMap<K, CacheEntry<V>> cache = new HashMap<>();

    public void put(K key, V value, long ttlMilliseconds) {
        long expiryTime = System.currentTimeMillis() + ttlMilliseconds;
        cache.put(key, new CacheEntry<>(value, expiryTime));
    }

    public V get(K key) {
        CacheEntry<V> entry = cache.get(key);
        if (entry != null && entry.expiryTime >= System.currentTimeMillis()) {
            return entry.value;
        }
        return null;
    }

    private static class CacheEntry<V> {
        private V value;
        private long expiryTime;

        public CacheEntry(V value, long expiryTime) {
            this.value = value;
            this.expiryTime = expiryTime;
        }
    }
}
```

### 基于数据访问模式的策略（LRU）

```java
import java.util.LinkedHashMap;
import java.util.Map;

public class LRUCache<K, V> extends LinkedHashMap<K, V> {
    private final int capacity;

    public LRUCache(int capacity) {
        super(capacity, 0.75f, true);
        this.capacity = capacity;
    }

    @Override
    protected boolean removeEldestEntry(Map.Entry<K, V> eldest) {
        return size() > capacity;
    }

    public static void main(String[] args) {
        LRUCache<Integer, String> cache = new LRUCache<>(3);
        cache.put(1, "One");
        cache.put(2, "Two");
        cache.put(3, "Three");
        System.out.println(cache); // Output: {1=One, 2=Two, 3=Three}
        cache.put(4, "Four");
        System.out.println(cache); // Output: {2=Two, 3=Three, 4=Four}
        cache.get(2); // Accessing key 2
        System.out.println(cache); // Output: {3=Three, 4=Four, 2=Two}
        cache.put(5, "Five");
        System.out.println(cache); // Output: {4=Four, 2=Two, 5=Five}
    }
}
```

以上示例分别演示了基于时间的缓存失效策略（TTL）和基于数据访问模式的缓存失效策略（LRU）的实现。通过这些示例，你可以根据具体的应用场景选择适合的缓存失效策略来提高系统的性能和效率。